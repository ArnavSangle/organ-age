\documentclass[10pt,twocolumn]{article}

% ============================================================
% Page layout (two-column)
% ============================================================
\usepackage[
  left=0.75in,
  right=0.75in,
  top=1in,
  bottom=1in,
  columnsep=0.25in
]{geometry}

% ============================================================
% Colors
% ============================================================
\usepackage[dvipsnames]{xcolor}

% ---- Stroke / accent colors (lighter blue + rose per your request) ----
\definecolor{OAslate}{HTML}{334155} % deep slate (strokes/text)
\definecolor{OAamber}{HTML}{B45309} % warm amber
\definecolor{OAteal}{HTML}{0F766E}  % teal

% Make these lighter than before:
\definecolor{OAblue}{HTML}{3B82F6}  % lighter blue (was darker)
\definecolor{OArose}{HTML}{F43F5E}  % lighter rose (was darker)

% Use a slightly stronger blue for links so they stay readable:
\definecolor{OAblueLink}{HTML}{2563EB}

% ---- Fill colors (very light) ----
\definecolor{OAfillRose}{HTML}{FCE7F3}
\definecolor{OAfillAmber}{HTML}{FFEDD5}
\definecolor{OAfillSage}{HTML}{ECFDF3}
\definecolor{OAfillTeal}{HTML}{E6FFFB}
\definecolor{OAfillBlue}{HTML}{EFF6FF}
\definecolor{OAfillSlate}{HTML}{F1F5F9}

% ---- Backward-compatible aliases (so your old figures don't break) ----
% If your figure uses fill=OAgray / OAcream / OAmint / OAblue / OArose, this keeps it compiling.
\colorlet{OAgray}{OAfillSlate}
\colorlet{OAcream}{OAfillAmber}
\colorlet{OAmint}{OAfillSage}
\colorlet{OAblueFill}{OAfillBlue}
\colorlet{OAroseFill}{OAfillRose}

% ============================================================
% Typography & spacing
% ============================================================
\usepackage{lmodern}           % better Latin Modern fonts (Type 1, vector)
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{microtype}
\microtypesetup{protrusion=true, expansion=true}

\tolerance=1000
\emergencystretch=2em
\hyphenpenalty=500
\exhyphenpenalty=500

\setlength{\parindent}{1em}
\setlength{\parskip}{0.3em}

\usepackage{titling}
\setlength{\droptitle}{-3em}

% ============================================================
% Section spacing
% ============================================================
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{0.8em}{0.4em}
\titlespacing*{\subsection}{0pt}{0.6em}{0.25em}
\titlespacing*{\subsubsection}{0pt}{0.4em}{0.2em}

\usepackage{etoolbox}
\makeatletter
\patchcmd{\@startsection}
  {\@afterindenttrue}
  {\@afterindentfalse}
  {}
  {}
\makeatother

% ============================================================
% Math / tables
% ============================================================
\usepackage{amsmath, amssymb}
\usepackage{booktabs}

% ============================================================
% Figures / floats (two-column)
% ============================================================
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{dblfloatfix}
\usepackage[section]{placeins}
\usepackage{float}

\setkeys{Gin}{width=\columnwidth, keepaspectratio}

\graphicspath{
  {figures/organ_age/}
  {figures/organ_age/v4_panels/}
  {figures/vitalis_v4/}
  {figures/vitalis_v4/GTEX-1117F/}
  {figures/v4_5/}
  {figures/v4_5/top_genes/}
}

\setcounter{topnumber}{2}
\setcounter{dbltopnumber}{2}
\renewcommand{\topfraction}{0.9}
\renewcommand{\dbltopfraction}{0.9}
\renewcommand{\textfraction}{0.08}
\renewcommand{\floatpagefraction}{0.85}
\renewcommand{\dblfloatpagefraction}{0.85}

\captionsetup{
  font=small,
  labelfont=bf,
  textfont=normalfont
}

% ============================================================
% TikZ
% ============================================================
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, fit}

% IMPORTANT:
% - Do NOT define a style named "step" (TikZ has a key "step=<len>").
% - Use OAstep / OAin instead.
\tikzset{%
  OAarrow/.style={-{Latex[length=2.2mm]}, line width=0.55pt, draw=OAslate},%
  % INPUT nodes (small boxes on top)
  OAin/.style={%
    draw=OAslate!70, rounded corners=2.2mm, line width=0.40pt, align=center,
    inner xsep=6pt, inner ysep=4.5pt, minimum width=0.27\columnwidth,
    fill=OAfillSlate
  },%
  % PIPELINE step nodes
  OAstep/.style={%
    draw=OAslate, rounded corners=2.2mm, line width=0.45pt, align=center,
    inner xsep=6.5pt, inner ysep=5.5pt, minimum width=0.86\columnwidth
  },%
  % Stage fills (apply as: [OAstep, stageBlue], etc.)
  stageRose/.style={fill=OAfillRose},%
  stageAmber/.style={fill=OAfillAmber},%
  stageSage/.style={fill=OAfillSage},%
  stageTeal/.style={fill=OAfillTeal},%
  stageBlue/.style={fill=OAfillBlue},%
  stageSlate/.style={fill=OAfillSlate}%
}

% ============================================================
% Citations + hyperlinks (hyperref late)
% ============================================================
\usepackage{cite}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=OAblueLink,
  citecolor=OAblueLink,
  urlcolor=OAblueLink
}

% ============================================================
% Title and Author
% ============================================================
\title{Organ-Age: Multimodal Fusion of Transcriptomic and Radiological Signals for Organ-Resolved Biological Age Estimation}
\author{
  Arnav Sangle, Independent Researcher, Ranchview High School, Irving TX, USA \\
  \texttt{arnavsangle08@gmail.com}
}
\date{}

\begin{document}

% Full-width title + abstract block in a two-column paper
\makeatletter
\twocolumn[
\begin{@twocolumnfalse}
\maketitle
\vspace{-2em}
\noindent\rule{\textwidth}{0.4pt}
\vspace{0em}




\begin{abstract}
Biological aging does not proceed uniformly across the body---different organs accumulate 
molecular, structural, and physiological damage at different rates. Yet most biological age 
predictors rely on a single data type, usually molecular measurements, and consequently 
cannot distinguish organ-specific aging trajectories that span both gene expression and 
medical imaging. Here I present Organ-Age, a framework that estimates organ-level biological 
age by fusing transcriptomic and radiological data. Working with a combined dataset of over 
190,000 samples, I first align modality-specific embeddings into a common latent space via 
contrastive learning, then merge them through a transformer-based fusion module to produce 
organ-resolved age predictions. The final model achieves a mean absolute error of 
$\sim$9.3 years and tracks chronological age closely across the adult lifespan. Residual 
deviations between predicted organ age and chronological age---organ-age deltas---expose 
patterns of accelerated and decelerated aging that are consistent with known tissue-level 
biology, indicating that the fused representation encodes variation beyond chronological 
time. These findings show that aligning and merging heterogeneous aging signals is a 
viable route toward organ-resolved biological age assessment.
\end{abstract}


\vspace{1em}
\noindent\rule{\textwidth}{0.4pt}
\vspace{1em}
\end{@twocolumnfalse}
]
\makeatother




\section{Introduction}

Biological aging involves progressive functional decline at the molecular, cellular, and organ
levels. Chronological age is a crude proxy for this process---individuals of the same calendar
age vary widely in their healthspan, disease burden, and rate of physiological deterioration.
Recognizing this, a growing body of work has sought to estimate biological age: a quantity
that reflects actual physiological state rather than time since birth
\cite{horvath2013,hannum2013}.

The most established biological age predictors are epigenetic clocks, which use DNA
methylation patterns to estimate a single, organism-wide age value. These clocks correlate
well with mortality, chronic disease risk, and functional decline \cite{levine2018}, and they
have been instrumental in showing that aging is, in principle, quantifiable from molecular
data. However, because they collapse the aging signal into one number, they say little about
how individual tissues or organs age relative to one another---a distinction that matters
clinically, since age-related pathology is often organ-specific.

A growing literature confirms that aging is not synchronous across the body. Lungs in chronic
smokers and livers in heavy drinkers deteriorate well ahead of other organs in the same
individual. More broadly, tissue-resolved and single-cell profiling studies have documented
wide variation in the pace and character of age-associated molecular change across organ
systems \cite{zakarpolyak2023}. Despite this, few computational approaches attempt to
estimate organ-specific biological age directly. Most existing models work from a single data
type---gene expression, imaging, or methylation---and therefore capture only part of the
picture.

On the imaging side, deep learning models trained on chest radiographs and brain MRI have
shown that macrostructural aging features---changes in skeletal morphology, soft-tissue
composition, and brain volume---can be read off medical images with reasonable accuracy
\cite{cole2017,rajpurkar2018chexnet}. These structural cues are largely invisible to
molecular clocks, and vice versa; yet imaging-based age predictors are typically developed in
isolation, with no connection to the underlying molecular state of the tissue.

Multimodal learning offers a natural way to bridge this gap. Contrastive objectives such as
InfoNCE and its descendants can pull embeddings from different data types into a common
representation space, preserving the structure within each modality while encouraging
cross-modal agreement \cite{oord2018cpc,chen2020simclr,radford2021clip}.
Transformer-based architectures add the ability to model interactions across modalities
through attention \cite{vaswani2017}, and recent systems like Perceiver IO and FLAVA have
demonstrated that diverse inputs can be merged through a shared latent bottleneck without
requiring pixel-level or token-level alignment
\cite{jaegle2021perceiver,singh2021flava}. Separately, probabilistic regression methods have
emphasized the value of predicting uncertainty alongside point estimates, which is especially
relevant for targets like biological age that are inherently noisy and never directly observed
\cite{kendall2017}. Taken together, these lines of work suggest that biological age may be
better understood as a composite quantity---shaped by the interplay of molecular and
structural processes---than as something derivable from any single measurement.

With this motivation, I present Organ-Age, a framework for estimating organ-level biological
age by jointly modeling transcriptomic and radiological signals. Separate encoders produce
embeddings from RNA-seq data, chest radiographs, and structural MRI scans; these embeddings
are pulled into a shared latent space through contrastive alignment and then merged by a
transformer-based fusion module to yield organ-specific age predictions. A central focus of
the work is the interpretation of residual deviations between predicted organ age and
chronological age, which can flag accelerated or decelerated aging in particular tissues.


\begin{figure}[t]
\centering
\begin{tikzpicture}[
  font=\small,
  node distance=4.6mm
]

% --- Top inputs (compact) ---
\node[OAin] (rna) {RNA\\(GTEx)};
\node[OAin, right=4.5mm of rna] (xray) {X-ray\\(CheXpert)};
\node[OAin, right=4.5mm of xray] (mri) {MRI\\(IXI)};

% --- Vertical pipeline ---
\node[OAstep, stageAmber, below=7.5mm of xray] (enc)
  {\textbf{Modality Encoders}\\{\footnotesize (learn embeddings)}};

\node[OAstep, stageTeal, below=of enc] (align)
  {\textbf{Contrastive Alignment}\\{\footnotesize (shared latent space)}};

\node[OAstep, stageBlue, below=of align] (fuse)
  {\textbf{Fusion Transformer}\\{\footnotesize (cross-modal attention)}};

\node[OAstep, stageRose, below=of fuse] (pred)
  {\textbf{Organ-Age Prediction}\\{\footnotesize $\hat{y}$ and uncertainty}};

\node[OAstep, stageSlate, below=of pred] (gap)
  {\textbf{Organ-age gap}\\{\footnotesize $\Delta=\hat{y}-y$}};

% --- Arrows (inputs into first stage) ---
\draw[OAarrow] (rna.south) -- ++(0,-3.2mm) -| (enc.north);
\draw[OAarrow] (xray.south) -- (enc.north);
\draw[OAarrow] (mri.south) -- ++(0,-3.2mm) -| (enc.north);

% --- Vertical arrows ---
\draw[OAarrow] (enc) -- (align);
\draw[OAarrow] (align) -- (fuse);
\draw[OAarrow] (fuse) -- (pred);
\draw[OAarrow] (pred) -- (gap);

\end{tikzpicture}
\caption{Conceptual overview of Organ-Age: modality-specific encoders, alignment, fusion, 
and organ-age prediction with uncertainty and age-gap outputs.}
\label{fig:conceptual_overview}
\end{figure}


Figure~\ref{fig:conceptual_overview} outlines the Organ-Age pipeline. The core idea is that
organ-specific biological age reflects the joint contribution of molecular and structural
signals, and that aligning representations from these domains can surface aging patterns
invisible to any single modality. Beyond population-level evaluation, Organ-Age also supports
per-subject interpretation through individualized organ-age panels (v4) and gene-level
attribution summaries (v4.5), which trace organ-age deviations back to candidate
transcriptomic drivers.




\section{Methods}

Three publicly available datasets supply the molecular and structural aging signals used in
this work. Transcriptomic data come from the Genotype-Tissue Expression (GTEx) v10 release,
which contains bulk RNA-seq profiles across dozens of human tissues sampled from adult donors
\cite{gtex2017}. Radiological data come from CheXpert, a large collection of frontal chest
radiographs with associated demographic metadata \cite{irvin2019chexpert}. Structural brain
imaging comes from the IXI dataset, which provides T1-weighted MRI scans from healthy adults
spanning a broad age range \cite{ixi2020}. Samples without reliable age labels or that failed
quality-control filters were dropped before any modeling.

Each data type was preprocessed according to standard domain-specific protocols. Gene
expression counts were variance-stabilized following the DESeq2 approach \cite{deseq2}, and
batch effects from site and technical sources were corrected with ComBat \cite{combat2007}.
Chest radiographs were resized and intensity-normalized, then passed through convolutional
backbones initialized from pretrained ResNet weights \cite{he2016resnet}; transfer-learning
practices from BiT \cite{kolesnikov2020bit} guided the fine-tuning strategy. MRI volumes
were skull-stripped, intensity-normalized, and nonlinearly registered to a common template
with ANTs \cite{avants2007ants}, supplemented by standard FSL preprocessing steps
\cite{smith2004fsl}.

A separate encoder network handles each modality. For transcriptomics, a feedforward network
maps normalized expression vectors to a fixed-length embedding. For chest X-rays and MRI
scans, convolutional networks---adapted to 2-D and 3-D inputs, respectively---serve the
same purpose. All three encoders output embeddings of the same dimensionality so that they
can be compared and merged downstream.

To bring these modality-specific embeddings into a common space, I appended learned
projection heads to each encoder and trained them with an InfoNCE-style contrastive objective
\cite{oord2018cpc}, borrowing design choices from SimCLR and CLIP
\cite{chen2020simclr,radford2021clip}. Pairwise similarity is measured by cosine similarity,
which depends on the angle between vectors and is insensitive to their magnitude:
\begin{equation}
\mathrm{sim}(u, v) = \frac{u^\top v}{\|u\| \|v\|}
\label{eq:cosine}
\end{equation}

Alignment was optimized by minimizing the contrastive loss
\begin{equation}
\mathcal{L}_{\text{InfoNCE}}
=
- \log 
\frac{\exp(\mathrm{sim}(u,u') / \tau)}
{\sum_{j} \exp(\mathrm{sim}(u,u_j)/\tau)}
\label{eq:infonce}
\end{equation} 
which pushes embeddings from the same biological context closer together while
pulling apart those from unrelated samples.


\begin{figure}[t!]
\centering
\begin{tikzpicture}[
  font=\small,
  inmod/.style={
    draw=OAslate!70, rounded corners=3pt, align=center, inner sep=4pt,
    minimum width=2.1cm, minimum height=0.85cm, fill=OAfillSlate
  },
  enc/.style={
    draw=OAslate, rounded corners=4pt, align=center, inner sep=6pt,
    minimum width=2.9cm, minimum height=0.95cm, fill=OAfillAmber
  },
  proj/.style={
    draw=OAslate, rounded corners=4pt, align=center, inner sep=6pt,
    minimum width=2.9cm, minimum height=0.95cm, fill=OAfillTeal
  },
  loss/.style={
    draw=OAslate, rounded corners=4pt, align=center, inner sep=6pt,
    minimum width=2.9cm, minimum height=0.95cm, fill=OAfillRose
  },
  arrow/.style={-Stealth, thick, draw=OAslate!80},
  dashedarrow/.style={-Stealth, thick, draw=OAslate!60, dashed}
]

\node[inmod] (rna) {RNA\\$x_{\mathrm{RNA}}$};
\node[inmod, right=0.65cm of rna] (xray) {X-ray\\$x_{\mathrm{XR}}$};
\node[inmod, right=0.65cm of xray] (mri) {MRI\\$x_{\mathrm{MRI}}$};

\node[enc,  below=0.55cm of xray] (encs)  {Encoders\\$f_m(\cdot)$};
\node[proj, below=0.50cm of encs] (projh) {Projection heads\\$g_m(\cdot)$};
\node[loss, below=0.50cm of projh] (cl)   {Contrastive loss\\{\footnotesize (shared latent)}};

\draw[arrow] (rna)  -- (encs);
\draw[arrow] (xray) -- (encs);
\draw[arrow] (mri)  -- (encs);
\draw[arrow] (encs) -- (projh);
\draw[arrow] (projh) -- (cl);

% Vertical note box under RNA (rotate BOX ONLY; text stays upright)
\node[
  draw=OAslate!55,
  rounded corners=3pt,
  fill=OAfillSlate,
  align=left,
  inner sep=5pt,
  text width=1.55cm,          % skinny
  minimum height=3.05cm,      % tall
  shape border rotate=90,     % rotate border only (NOT the text)
  below=0.95cm of rna         % lower under RNA
] (note)
{\textbf{Goal:} modality-invariant\\age structure \,+ robust fusion};

% Dashed connector from note toward loss
\draw[dashedarrow]
  (note.south) -- ++(0,-0.25) |- (cl.west);

\end{tikzpicture}

\caption{
\textbf{Contrastive representation alignment.}
Each modality is encoded and passed through a projection head; a contrastive objective
encourages embeddings from different modalities to occupy a shared latent space that preserves
age-related structure while reducing modality-driven separation.
}
\label{fig:contrastive_alignment}
\end{figure}


Figure~\ref{fig:contrastive_alignment} diagrams this alignment step.

Once aligned, the modality embeddings are combined by a transformer-based fusion module.
Instead of simple concatenation or prediction averaging, the fusion model uses self-attention
to learn cross-modal interactions, letting molecular and radiological information contribute
in a data-dependent way. Given aligned embeddings
$\{z^{(1)}, z^{(2)}, \dots, z^{(M)}\}$ from $M$ modalities, the fused representation is
\begin{equation}
z_{\text{fusion}} = f_{\text{Transformer}}\left(
z^{(1)}, z^{(2)}, \dots, z^{(M)}
\right)
\label{eq:fusion}
\end{equation}
The design follows Perceiver IO and FLAVA \cite{jaegle2021perceiver,singh2021flava},
adapted to work on continuous biomedical embeddings rather than raw pixels or tokens.


\begin{figure}[t!]
\centering
\begin{tikzpicture}[
  font=\small,
  node distance=4.8mm
]

\node[OAstep, stageBlue] (pred)
  {\textbf{Predict}\\{\footnotesize $\hat{y}$ \,+ uncertainty}};

\node[OAstep, stageAmber, below=of pred] (cal)
  {\textbf{Calibrate}\\{\footnotesize $\hat{y}\rightarrow \hat{y}_{\mathrm{cal}}$}};

\node[OAstep, stageTeal, below=of cal] (ci)
  {\textbf{CI / intervals}\\{\footnotesize (interpretability)}};

\node[OAstep, stageSage, below=of ci] (gap)
  {\textbf{Age-gap}\\{\footnotesize $\Delta=\hat{y}_{\mathrm{cal}}-y$}};

\node[OAstep, stageRose, below=of gap] (z)
  {\textbf{Standardize}\\{\footnotesize $z=\Delta/\sigma_{\mathrm{organ}}$}};

\node[OAstep, stageSlate, below=of z] (panel)
  {\textbf{Subject panel}\\{\footnotesize (organ-level summary)}};

\draw[OAarrow] (pred) -- (cal);
\draw[OAarrow] (cal) -- (ci);
\draw[OAarrow] (ci) -- (gap);
\draw[OAarrow] (gap) -- (z);
\draw[OAarrow] (z) -- (panel);

\end{tikzpicture}
\caption{Post-processing and interpretability pathway: calibration, uncertainty intervals, 
age-gap computation, standardization, and subject-level organ summaries.}
\label{fig:fusion_transformer}
\end{figure}


Figure~\ref{fig:fusion_transformer} shows the post-fusion processing pipeline.

The fused representation is fed to a probabilistic regression head that outputs both a point
estimate and a learned uncertainty term, rather than a bare scalar prediction. Concretely,
the head produces


\begin{equation}
(\mu, \sigma^2) = g_{\theta}(z_{\text{fusion}})
\label{eq:age_prediction}
\end{equation}


where $g_{\theta}(z_{\text{fusion}})$ is the regression head with parameters $\theta$.
The training objective is a Gaussian negative log-likelihood \cite{kendall2017}


\begin{equation}
\mathcal{L}_{\text{NLL}}
=
\frac{1}{2}\log\sigma^2
+
\frac{(\mu-y)^2}{2\sigma^2}
\label{eq:gnll}
\end{equation}
so that the model is incentivized to widen its uncertainty estimate when its
predictions are poor, rather than absorbing all error into the mean.

Training follows a staged curriculum: first the modality-specific encoders are trained
independently, then the contrastive alignment and fusion stages are optimized jointly. The
combined loss is


\begin{equation}
\mathcal{L}_{\text{total}}
=
\lambda_{\text{align}} \mathcal{L}_{\text{InfoNCE}}
+
\lambda_{\text{reg}} \mathcal{L}_{\text{NLL}}
\label{eq:total_loss}
\end{equation}
where $\lambda_{\text{align}}$ and $\lambda_{\text{reg}}$ weight the two terms. Both
coefficients were set on a held-out validation split and kept fixed thereafter.

Regularization during optimization draws on the variational information bottleneck
\cite{alemi2016vib}. The full training procedure---encoder pretraining, contrastive
alignment, and fusion---was run sequentially, with each stage warm-starting from the
previous checkpoint.

Beyond population-level metrics, Organ-Age provides per-subject outputs: individualized
organ-deviation panels (v4) and gene-level attribution summaries that trace organ-age
residuals back to specific transcripts (v4.5).




\section{Results}

I evaluated the model in three configurations---unimodal, na\"ive multimodal fusion, and
contrastively aligned multimodal fusion---to tease apart what each component contributes.
Performance is reported as mean absolute error (MAE) and mean squared error (MSE), alongside
qualitative inspection of predicted-versus-chronological-age plots.



\subsection{Population-level behavior in the normative setting}

I first looked at each modality in isolation to understand what aging information it carries
on its own. The RNA encoder, trained on GTEx expression data, picked up age-associated
molecular patterns across tissues and produced predictions that tracked chronological age with
moderate scatter. Variance grew at older ages, consistent with the well-documented increase
in transcriptomic heterogeneity among older individuals. On its own, however, the RNA
encoder lacked structural context and could not resolve organ-level anatomy.

The chest X-ray encoder learned macrostructural aging features---skeletal morphology, cardiac
silhouette, and soft-tissue changes---and its predictions correlated clearly with chronological
age. Yet the predicted ages clustered tightly around the population mean, suggesting that the
model captures a robust but generic aging trend while being relatively insensitive to
individual-level variation. In other words, population-level correlation was preserved, but
the effective prediction range was compressed, with age-gap variance attenuated. The MRI
encoder showed a similar pattern: monotonic age trends were recovered from T1-weighted brain
scans, but predictions were confined to organ-local information and offered little insight
into cross-organ or systemic aging when used alone. In short, each unimodal encoder picks up
stable aging correlates within its domain, enough for coarse population-level estimation, but
none of them alone captures the full picture of individualized biological aging.


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{normative_pred_vs_chrono_all.png}
\caption{
\textbf{Overall prediction behavior across the population (normative setting).}
Predicted biological age versus chronological age for the aggregated cohort.
}
\label{fig:pred_vs_chrono_all_normative}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{normative_gap_vs_chrono_all.png}
\caption{
\textbf{Age-gap behavior across the population (normative setting).}
Difference between predicted biological age and chronological age as a function of chronological age.
}
\label{fig:gap_vs_chrono_all_normative}
\end{figure}


As a first attempt at combining modalities, I built a baseline fusion model (v3) that simply
concatenates the modality-specific embeddings without any prior alignment step. This already
reduced prediction error relative to the unimodal baselines---evidence that molecular and
radiological signals carry complementary information. But the latent representations still
separated largely by modality, producing inconsistent fusion behavior across samples and
unstable organ-level age estimates.


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{normative_gap_hist_all.png}
\caption{
\textbf{Organ-age gap distribution (normative setting).}
Histogram of $\Delta=\hat{y}-\mathrm{Age}_{\text{true}}$ summarizing the distribution of accelerated 
(positive) and decelerated (negative) aging deviations across the cohort.
}
\label{fig:organ_age_gap_hist_normative}
\end{figure}


In the normative setting, these cohort-wide plots serve as a basic sanity check: predictions
are broadly monotonic with age, and the residual distribution shows how tightly deviations
cluster around the population trend.



\subsection{Impact of contrastive alignment on multimodal fusion (v3.5)}

The shortcomings of na\"ive fusion led me to introduce contrastive alignment before the
fusion stage. Pulling modality-specific embeddings into a common latent space cut
inter-modality variance and allowed the fusion module to integrate signals more reliably,
even when not all modalities were available for a given sample. The resulting model (v3.5)
achieved an MAE of $\sim$9.3 years across the full 195k-sample dataset---a clear gain over
both the unimodal encoders and the unaligned fusion baseline.


\begin{table}[t]
\centering
\caption{
\textbf{Performance of contrastively aligned multimodal fusion (v3.5).}
Mean squared error (MSE) and mean absolute error (MAE) are reported across modalities for the cross-fusion 
model trained on aligned representations. Contrastive alignment improves performance consistently across 
transcriptomic, radiological, and MRI modalities.
}

\begin{tabular}{lrcc}
\toprule
\textbf{Modality} & \textbf{N} & \textbf{MSE} & \textbf{MAE (yr)} \\
\midrule
All    & 195,766 & 138.00 & 9.30 \\
RNA    &   7,378 & 139.44 & 9.16 \\
X-Ray  & 187,825 & 138.18 & 9.31 \\
MRI    &     563 &  61.92 & 6.21 \\
\bottomrule
\end{tabular}
\label{tab:v35_results}
\end{table}


The improvement held across all three modalities (Table~\ref{tab:v35_results}), which
suggests that alignment makes each modality a better contributor to the fused representation,
rather than one modality dominating.

To visualize what alignment does to the latent space, I projected unaligned and aligned
embeddings with UMAP \cite{mcinnes2018umap}. Before alignment, points clustered by modality,
meaning domain identity was the dominant axis of variation. After alignment, modality clusters
overlapped substantially and organized instead along age-related gradients---a sign that the
contrastive objective succeeded in extracting shared aging structure.

The bottom-line outcome of Organ-Age is the organ-age gap:


\begin{equation}
\Delta = \hat{y} - \mathrm{Age}_{\text{true}}
\label{eq:agegap}
\end{equation}


In the aligned model, predicted ages tracked chronological age in a tight linear band, with
noticeably less scatter than either the unimodal or unaligned-fusion models. Deviations from
the identity line---positive or negative---correspond to organs aging faster or slower than
expected, in line with the biological age gap literature \cite{belsky2020dunedinpace}.
Compared to the baseline, the aligned model produced smoother residuals, reduced
heteroscedasticity, and more stable estimates across the full adult age range.



\subsection{Calibrated outputs and uncertainty-aware prediction}

I applied post-hoc calibration to put predicted ages on a scale more directly comparable to
chronological age and to make residuals comparable across organs.
Figure~\ref{fig:calibrated_pred_with_ci} shows the result: after calibration, predicted
biological age tracks chronological age along an approximately linear trend with little
systematic offset, while the monotonic structure of the aging signal is preserved. The
confidence intervals widen at older ages, reflecting both greater inter-individual variability
and sparser data at the upper end of the age range. These intervals give context to
organ-age deviations and make cross-organ and cross-subject comparisons more meaningful.


\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{calibrated_pred_vs_chrono_with_ci.png}
\caption{
\textbf{Calibrated organ-age prediction with uncertainty.}
Calibrated predicted biological age with a 95\% confidence interval compared to chronological age.
}
\label{fig:calibrated_pred_with_ci}
\end{figure}



\subsection{Per-organ calibrated prediction behavior}

To show that organ aging is not uniform, I break out the calibrated results for four
representative organs. These per-organ plots also double as diagnostics: a strong residual
trend with chronological age would flag calibration drift or systematic bias.
Figure~\ref{fig:calibrated_overlay_summary}
confirms that all four organs exhibit roughly monotonic predicted--versus--chronological-age
relationships, but they differ in dispersion and residual structure. Some organs cluster
tightly around the identity line; others show wider spread, consistent with differences in
biological variability and measurement sensitivity across tissues.

The age-gap trajectories and organ-specific histograms tell the same story at finer
resolution. For several organs the residuals stay centered near zero across the whole age
range, indicating good calibration with minimal systematic bias. For others, mild
age-dependent variance or residual trends remain---organ-specific patterns that would be
washed out in a pooled analysis. The density overlay in
Figure~\ref{fig:calibrated_overlay_summary} consolidates all organ gap distributions on a
shared axis, making cross-organ differences immediately visible while keeping the figure
compact enough to stay in the local text flow.
These differences underscore why organ-resolved evaluation
matters and motivate the individualized analyses that follow.


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{calibrated_overlay_summary_key_organs.png}
\caption{
\textbf{Calibrated organ-age overlays for key organs.}
Compact three-view summary for four representative organs (brain, brain cortex, heart, lung):
\textit{top-left} overlay of predicted biological age vs.\ chronological age, \textit{top-right}
overlay of age-gap trajectories $\Delta = \hat{y} - \mathrm{Age}_{\text{true}}$, and
\textit{bottom} density-normalized age-gap distributions. Overlaying organ traces in one
frame preserves cross-organ comparability without requiring separate pages of subfigures.
}
\label{fig:calibrated_overlay_summary}
\end{figure}



\subsection{Hero subject analysis (Vitalis v4): individualized organ-age profiling}

While cohort-level metrics validate overall model behavior, individualized interpretation
is the intended endpoint of Organ-Age. A single "hero subject" analysis illustrates how
calibrated organ-age outputs can be summarized as organ deltas, uncertainty intervals, and 
standardized z-scores for readable interpretation.


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{1117F_panel.png}
\caption{
\textbf{Hero subject (Vitalis v4): organ-level deviation profile.}
Per-organ age-gap bars for subject GTEX-1117F with organ-wise z-score annotations. This
compact view highlights which organs are most accelerated or decelerated relative to
chronological age.
}
\label{fig:vitalis_hero_stack}
\end{figure}


To preserve the full individualized context, I also show the corresponding uncertainty and
shape-profile diagnostics for the same subject (Figure~\ref{fig:vitalis_hero_ci_radar}).
These complementary views help separate a large but uncertain organ deviation from a
small but stable one, and they reveal whether outlier burden is diffuse or concentrated in
one or two organs.

\begin{figure}[t]
\centering
\begin{subfigure}[t]{0.49\linewidth}
\centering
\includegraphics[width=\linewidth]{ci_plot.png}
\caption{Calibrated organ ages with 95\% CI.}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.49\linewidth}
\centering
\includegraphics[width=\linewidth]{radar.png}
\caption{Standardized organ z-score profile.}
\end{subfigure}
\caption{
\textbf{Hero subject (Vitalis v4): complementary uncertainty and z-score diagnostics.}
The CI panel shows uncertainty-aware organ ages around the chronological baseline, while
the radar panel summarizes relative organ burden in standardized units.
}
\label{fig:vitalis_hero_ci_radar}
\end{figure}

In interpretation, these organ-level deviations are treated as correlation signals rather
than direct causal diagnoses. Across subjects, an older-appearing lung profile can correlate
with smoking exposure or chronic pulmonary stress, and an older-appearing liver profile can
correlate with alcohol burden, fatty-liver biology, or metabolic strain. Conversely, younger-
appearing multi-organ profiles can correlate with favorable physical conditioning and lower
cardiometabolic risk. Confirming any specific mechanism still requires clinical metadata and
longitudinal follow-up.

\subsection{Molecular interpretability (v4.5): gene-level attribution of organ-age signals}

A model that predicts organ age accurately but offers no molecular insight is of limited
scientific value. The v4 panels show \emph{which} organs deviate; the v4.5 extension asks
\emph{why}, by identifying which genes drive the organ-age predictions. I report two
complementary attribution analyses.

First, gene-ranking analyses list the individual genes whose expression patterns are most
strongly associated with predicted organ age---an immediate, readable summary of candidate
molecular contributors. Second, integrated gradients computed over the latent RNA dimensions
show how the model organizes transcriptomic information internally and which latent factors
matter most for each organ. Between them, these two views move from a black-box age
prediction toward concrete molecular hypotheses.


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{top_20_genes_rank_overlay.png}
\caption{
\textbf{Gene-level attribution (v4.5): rank overlay of top-gene importance by organ.}
Importance scores across ranks (top 20 genes per organ) are overlaid for representative
organs, enabling compact cross-organ comparison of attribution concentration and tail decay.
}
\label{fig:top20_genes_panel}
\end{figure}


Figure~\ref{fig:top20_genes_panel} shows that attribution concentration differs by organ:
some organs have a steeper rank-decay curve (importance concentrated in fewer genes), while
others distribute weight more broadly across the top-ranked set. This divergence is
reassuring: if the model were recovering only a single global age correlate, the rank curves
would be nearly identical across tissues. Instead, the organ-specific overlays suggest that
the predictor is using tissue-contextualized expression structure.

These rankings should be read as associations with the model's predictions, not as causal
drivers of aging. Even so, they provide a reasonable starting point for follow-up work:
pathway enrichment, comparison with known age-associated expression signatures, and targeted
validation in longitudinal or disease-specific cohorts. In effect, the gene-ranking panel
bridges the gap between a high-dimensional multimodal predictor and interpretable molecular
hypotheses.

While gene-ranking analyses provide direct feature-level interpretability, Organ-Age's RNA encoder
operates through a learned low-dimensional embedding. To probe how transcriptomic information is 
structured within this representation, integrated gradients were computed with respect to the latent 
RNA dimensions under organ-specific prediction settings. This latent-space attribution complements 
gene-level rankings by revealing how the model internally compresses and organizes age-relevant 
transcriptomic variation prior to multimodal fusion.


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{ig_three_overlay_rna.png}
\caption{
\textbf{Latent-space feature importance (RNA): cross-organ rank overlay.}
Integrated-gradient-derived latent importance over rank for representative organs, highlighting
how attribution mass concentrates in a small subset of dimensions.
}
\label{fig:ig_three_panel_rna}
\end{figure}


Figure~\ref{fig:ig_three_panel_rna} shows that attribution mass is concentrated on a handful
of latent RNA dimensions rather than spread evenly across the embedding. This sparsity
suggests the model distills transcriptomic aging signals into a small set of reusable factors,
which is desirable for both stability and downstream interpretability. Some latent dimensions
contribute broadly across organs, while others are organ-preferential---consistent with a
decomposition into shared systemic aging signals and tissue-specific programs.


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{ig_liver_rna_top20.png}
\caption{
\textbf{Latent RNA features driving liver biological age with cumulative overlay.}
Top latent RNA dimensions (bars) and cumulative attribution fraction (line) for liver age prediction.
}
\label{fig:ig_liver_rna_top20}
\end{figure}


Figure~\ref{fig:ig_liver_rna_top20} zooms in on the liver, where a few latent dimensions
account for most of the attribution magnitude. This sparsity means that liver age predictions
hinge on a compact transcriptomic signal, not on diffuse sensitivity across the whole
embedding. These dominant dimensions offer a natural entry point for deeper investigation:
each can be examined through its gene loadings or pathway correlations, creating a
multi-layered interpretability path from organ-age deviations down to candidate molecular
mechanisms.

Taken together, the v4.5 analyses show that Organ-Age supports molecular interpretability at
two complementary levels---individual genes and latent embedding structure---and that both
levels are organ-resolved. Combined with the v4 per-subject panels, they connect a person's
organ-age residuals to plausible molecular contributors, moving the framework from pure
prediction toward hypothesis generation.




\section{Discussion}

The experiments confirm that combining molecular and radiological data in a shared
representation measurably improves organ-level biological age estimation. The key ingredient
is contrastive alignment: without it, embeddings from different modalities occupy distinct
regions of the latent space, and the fusion module struggles to combine them in a stable way.
With alignment, transcriptomic, chest-X-ray, and MRI features intermix and can be fused
consistently, echoing a broader finding in the multimodal learning literature that
representation alignment is a prerequisite for reliable cross-modal integration
\cite{baltrusaitis2018survey}. For aging research specifically, the implication is that
biological age is better thought of as a composite construct shaped by signals at multiple
biological scales than as something any one modality can fully capture.

Relative to existing biological age predictors, Organ-Age adds organ-level resolution.
Epigenetic and transcriptomic clocks quantify systemic molecular aging but are blind to
anatomy; imaging-based models read off structural aging but have no access to the underlying
molecular state \cite{putin2016deepaging}. By training on both domains jointly, the present
framework can produce age-gap estimates that reflect structural \emph{and} regulatory change,
which should make the resulting deviations more interpretable than those from single-modality
models.

The organ-age deviations themselves are consistent with the broader biological age gap
literature, where divergence from chronological age has been linked to differences in
healthspan and disease risk. In Organ-Age, these deviations fall out of the fused
representation directly---they are not imposed through post-hoc correction---which lends some
confidence that the latent space has learned genuine age-related structure. The smoother
residual behavior and reduced heteroscedasticity in the aligned model compared to the
unaligned baseline reinforce this interpretation.

At the individual level, the v4 organ-age panels distill the model's output into a compact
report showing which organs are aging faster or slower than expected and by how much. This is
considerably more informative than a single biological-age number and makes it easier to
pinpoint which organ systems are driving an overall deviation. The v4.5 gene attribution
analysis adds a molecular layer: for each organ, it lists the transcripts most associated with
the predicted age, giving researchers concrete candidates for follow-up analyses---pathway
enrichment, comparison to published aging gene sets, or targeted validation in longitudinal
cohorts.

Several limitations deserve mention. The three datasets do not overlap at the individual
level, so the alignment operates on representations rather than matched samples; this
increases flexibility but complicates any causal interpretation across modalities. The
framework currently covers adult aging only and makes no attempt to model developmental or
early-life trajectories. And while the probabilistic regression head yields an uncertainty
estimate, cleanly separating epistemic from aleatoric uncertainty remains an open problem.

Natural next steps include adding proteomics, metabolomics, or longitudinal clinical data as
further modalities; incorporating iterative training strategies in which the model revisits
uncertain predictions to refine its representations
\cite{yao2022react,shinn2023reflexion}; and evaluating the framework longitudinally to test
whether organ-age deviations predict clinically meaningful outcomes.




\section{Conclusion}

I have presented Organ-Age, a framework that estimates organ-level biological age by
aligning and fusing transcriptomic and radiological representations. Contrastive alignment
pulls modality-specific embeddings into a shared latent space; a transformer-based fusion
module then combines them to yield organ-resolved age predictions.

On a dataset of over 190,000 samples, the aligned multimodal model outperformed both
unimodal encoders and an unaligned fusion baseline in predictive accuracy and latent-space
coherence. The resulting organ-age deviations expose patterns of accelerated and decelerated
aging that are biologically plausible, illustrating the advantage of combining molecular and
structural perspectives.

The v4 per-subject panels and the v4.5 gene-attribution summaries extend the framework
beyond raw prediction: the former distills organ-level deviations into a readable report, and
the latter traces those deviations to candidate transcriptomic drivers. Together they move
Organ-Age from a predictive tool toward a hypothesis-generating platform for studying how
individual organs age.

More broadly, these results argue that biological age is better modeled as a multi-signal,
organ-resolved quantity than as a single number. Organ-Age provides one concrete
instantiation of this idea and, I hope, a useful starting point for richer, more
interpretable aging models.




\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
